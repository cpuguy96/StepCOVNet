{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# StepCOVNet Training and Generation Demo\n",
    "\n",
    "This notebook demonstrates how to train StepCOVNet models (Onset and Arrow) and use them to generate a stepchart from an audio file.\n",
    "\n",
    "**StepCOVNet** is a deep learning-based stepchart generator for rhythm games like StepMania.\n",
    "\n",
    "The process involves:\n",
    "1.  Setting up the environment.\n",
    "2.  Downloading sample training data.\n",
    "3.  Training the Onset Model (detects timing of notes).\n",
    "4.  Training the Arrow Model (determines pattern of notes).\n",
    "5.  Generating a chart for a test song."
   ],
   "id": "9affb617dd239c5e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Environment Setup\n",
    "Clone the repository and install the package. We also configure TensorFlow to use the GPU if available for faster training."
   ],
   "id": "9eb6db6da76a4553"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Detect if we are running in Google Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Google Colab detected. Setting up environment...\")\n",
    "    if os.path.exists(\"StepCOVNet\"):\n",
    "        %cd StepCOVNet\n",
    "    elif not os.getcwd().endswith(\"StepCOVNet\"):\n",
    "        # Only clone if the folder doesn't already exist\n",
    "        !git clone https://github.com/cpuguy96/StepCOVNet.git\n",
    "        %cd StepCOVNet\n",
    "    !pip install -q .\n",
    "    print(\"Colab setup complete.\")\n",
    "else:\n",
    "    print(\"Local environment detected. Skipping Git clone.\")\n",
    "    print(\"Make sure you have run 'pip install .[dev]' or 'pip install .[gpu-dev]' in your terminal!\")"
   ],
   "id": "529ffe7a05b0d422",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check for GPU availability\n",
    "if tf.config.list_physical_devices(\"GPU\"):\n",
    "    import keras\n",
    "\n",
    "    print(\"Training with GPU.\")\n",
    "\n",
    "    # Use mixed precision for better performance on compatible GPUs\n",
    "    keras.mixed_precision.set_global_policy(\n",
    "        keras.mixed_precision.Policy(\"mixed_float16\")\n",
    "    )\n",
    "\n",
    "    # Enable XLA (Accelerated Linear Algebra) for TensorFlow, which can improve\n",
    "    # performance by compiling TensorFlow graphs into highly optimized\n",
    "    # machine code.\n",
    "    tf.config.optimizer.set_jit(\"autoclustering\")\n",
    "else:\n",
    "    print(\"Training on CPU. This might be slow.\")"
   ],
   "id": "bc8154e2461d0311",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Download Sample Data\n",
    "We will download a small subset of training data to demonstrate the training process. This dataset includes audio features and corresponding stepchart data."
   ],
   "id": "77e421c7864bb572"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import gdown\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# 1. The Drive ID of sampled_training_data zip\n",
    "file_id = '1dM8B30Fq-uWp-Dvi0PXGewZAnJ5T_KcP'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "output = 'stepcovnet_data.zip'\n",
    "\n",
    "# 2. Download the file\n",
    "print(\"Downloading data...\")\n",
    "gdown.download(url, output, quiet=False)\n",
    "\n",
    "# 3. Unzip it\n",
    "print(\"Unzipping...\")\n",
    "with zipfile.ZipFile(output, 'r') as zip_ref:\n",
    "    zip_ref.extractall('data/')  # Extracts to a 'data' folder\n",
    "\n",
    "# 4. Cleanup (Optional)\n",
    "os.remove(output)\n",
    "print(\"Done!\")"
   ],
   "id": "4404ab4bcb802fba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Verify data extraction\n",
    "!ls data"
   ],
   "id": "c1b522e68eff330",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Train Onset Model\n",
    "The **Onset Model** is responsible for detecting *when* a step should occur in the song. It looks at the audio spectrogram and predicts the probability of a step at each time frame.\n",
    "\n",
    "We define the data directories and training parameters below."
   ],
   "id": "e6e57765d7836563"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_data_dir = os.path.join(\"data\", \"train\")\n",
    "val_data_dir = os.path.join(\"data\", \"val\")\n",
    "callback_root_dir = \"callbacks\"\n",
    "model_output_dir = \"models\"\n",
    "model_name = \"example_onset_model\""
   ],
   "id": "c85670a8524d294d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Training Hyperparameters\n",
    "apply_temporal_augment = False  # Apply time stretching/shifting\n",
    "should_apply_spec_augment = False  # Apply frequency masking\n",
    "use_gaussian_target = False  # Use gaussian distribution for targets instead of binary\n",
    "gaussian_sigma = 0.0  # Sigma for gaussian target (if used)\n",
    "normalize = True  # Normalize input features\n",
    "batch_size = 1\n",
    "\n",
    "take_count = 1  # Number of batches to take per epoch (for demo purposes)\n",
    "epochs = 10  # Number of training epochs"
   ],
   "id": "e9088118304fc733",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from stepcovnet import trainers\n",
    "\n",
    "print(\"Starting Onset Model training...\")\n",
    "onset_model, onset_history = trainers.run_train(\n",
    "    data_dir=train_data_dir,\n",
    "    val_data_dir=val_data_dir,\n",
    "    batch_size=batch_size,\n",
    "    normalize=normalize,\n",
    "    apply_temporal_augment=apply_temporal_augment,\n",
    "    should_apply_spec_augment=should_apply_spec_augment,\n",
    "    use_gaussian_target=use_gaussian_target,\n",
    "    gaussian_sigma=gaussian_sigma,\n",
    "    model_params={},\n",
    "    take_count=take_count,\n",
    "    epoch=epochs,\n",
    "    callback_root_dir=callback_root_dir,\n",
    "    model_output_dir=model_output_dir,\n",
    "    model_name=model_name,\n",
    ")\n",
    "print(\"Onset Model training complete.\")"
   ],
   "id": "468d3bfa5a69639a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Train Arrow Model\n",
    "The **Arrow Model** decides *which* arrows (Left, Down, Up, Right) should be active for a given onset. It takes the audio context and the onset information to generate the pattern."
   ],
   "id": "328f30edf1ce15f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "arrow_train_data_dir = os.path.join(\"data\", \"train\")\n",
    "arrow_val_data_dir = os.path.join(\"data\", \"val\")\n",
    "arrow_callback_root_dir = \"callbacks\"\n",
    "arrow_model_output_dir = \"models\"\n",
    "arrow_model_name = \"example_arrow_model\""
   ],
   "id": "b3264eaa3d06456e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Training Hyperparameters\n",
    "normalize = True\n",
    "batch_size = 1\n",
    "\n",
    "take_count = 1\n",
    "epochs = 10"
   ],
   "id": "55fb987a4f4662ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from stepcovnet import trainers\n",
    "\n",
    "print(\"Starting Arrow Model training...\")\n",
    "arrow_model, arrow_model_history = trainers.run_arrow_train(\n",
    "    data_dir=arrow_train_data_dir,\n",
    "    val_data_dir=arrow_val_data_dir,\n",
    "    batch_size=batch_size,\n",
    "    normalize=normalize,\n",
    "    model_params={},\n",
    "    take_count=take_count,\n",
    "    epoch=epochs,\n",
    "    callback_root_dir=arrow_callback_root_dir,\n",
    "    model_output_dir=arrow_model_output_dir,\n",
    "    model_name=arrow_model_name,\n",
    ")\n",
    "print(\"Arrow Model training complete.\")"
   ],
   "id": "abfe9360f46fcddb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Generate Stepchart\n",
    "Now that we have trained both models, we can generate a full stepchart for a new song.\n",
    "We will use a test audio file (`tide.ogg`) included in the downloaded data."
   ],
   "id": "821576cf40823c52"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Make sure you run cells above to generate models\n",
    "audio_path = os.path.join(\"data\", \"test\", \"tide.ogg\")\n",
    "song_title = \"Tide\"\n",
    "bpm = 175"
   ],
   "id": "9a12dec4b4f7f502",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from stepcovnet import generator\n",
    "\n",
    "print(f\"Generating chart for {song_title}...\")\n",
    "output_data = generator.generate_output_data(\n",
    "    audio_path=audio_path,\n",
    "    song_title=song_title,\n",
    "    bpm=bpm,\n",
    "    onset_model=onset_model,\n",
    "    arrow_model=arrow_model,\n",
    ")\n",
    "print(f\"Finished generating chart for {song_title}.\")"
   ],
   "id": "139ae027828f560d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# View generated notes for tide.ogg\n",
    "# The output format is compatible with SMDataTools to convert into StepMania compatible type (.sm)\n",
    "print(output_data.generate_txt_output())"
   ],
   "id": "1ee5c2b118f79977",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
